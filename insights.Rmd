---
title: "subreddit insights"
output: html_notebook
---

Today we will look at [subreddits](https://youtu.be/pUncXbXAiV0). The data aggregates loaded here were created by converting pushshift [RS\*.zst](https://files.pushshift.io/reddit/submissions/) data into SQLITE format using the pushshift subcommand of the xklb python package:

```{fish}
wget -e robots=off -r -k -A zst https://files.pushshift.io/reddit/submissions/

pip install xklb

for f in psaw/files.pushshift.io/reddit/submissions/* 
    echo "unzstd --memory=2048MB --stdout $f | library pushshift (basename $f).db"
end | parallel -j4

library merge submissions.db psaw/RS*.db

# This takes several days per step and several terabytes but the end result is a 600 GB SQLITE file
```

But for this analysis you can get by with downloading the sub-100MB pre-aggregated files in this repo.

```{r}
require(data.table)

setwd('/home/xk/github/xk/reddit_mining')

stats_link = fread('zstdcat subreddit_stats_link.csv')
stats_text = fread('zstdcat subreddit_stats_text.csv')
stats_text
```

It seems like a lot of data is user subreddits so I will remove those because:

1.  they are less interesting
2.  they will need to be interpreted differently in any analysis
3.  I'm not sure how accurate they are because my user subreddit has only one record from four years ago. (Am I shadow banned??? I must be on some list somewhere because I also get 0 likes on bumble. oh well\~\~ The data analysis which [follows](https://youtube.com/watch?v=x8llJbEDA0g) is hopefully more interesting than my well-being)

```{r}
# fwrite(stats_link[subreddit %like% '^u_'], 'user_stats_link.csv')
# fwrite(stats_text[subreddit %like% '^u_'], 'user_stats_text.csv')
# 
# fwrite(stats_link[!(subreddit %like% '^u_')], 'subreddit_stats_link.csv')
# fwrite(stats_text[!(subreddit %like% '^u_')], 'subreddit_stats_text.csv')
```

The first thing that we can see is that about half of all subreddits only have one text post or one link post.

```{r}
data.table(sort(table(stats_text$count)))[N>32000]
data.table(sort(table(stats_link$count)))[N>96000]
```

But that may only be because some subreddits have only link posts enabled or only text posts enabled. We will need to create a third dataset to evaluate that:

```{r}
setkey(stats_link, "subreddit")
setkey(stats_text, "subreddit")
stats_both = stats_link[stats_text, nomatch=FALSE]

full_outer_join = merge(stats_link, stats_text, all=TRUE)
stats_uniq = full_outer_join[is.na(stats_link) | is.na(stats_text)]
rm(full_outer_join)
gc()

data.table(sort(table(stats_both$count + stats_both$i.count)))[N>96000]
```

Yes,

```{r}

```

```{r}
`

Dl = stats_link[sample(.N, 10000), ]
Dt = stats_link[sample(.N, 10000), ]

library(DataExplorer)
plot_density(Dl)
plot_density(Dt)
```
